大規模言語モデルにおける逆説的な(paradoxical)性質：

- 全般的な性能の予測可能な損失の減少（スケーリング則）
- 予測できない特定の能力、入出力の組み合わせ

1. ToC

- section 2 - 4 つの主張
  - スケーリング則と下流タスクの性能向上との相関、
  - 特定の能力の急激な成長、
  - オープンエンドの入力の問題点
  - オープンエンドの出力の問題点
- section 3 - 大規模生成モデルの増加が予測される理由
- section 4 - 政策介入

2-1. スケーリング則と下流タスクの性能向上との相関
複数の事例
![Alt text](<第2問図表/Screenshot 2023-08-22 at 21.51.22.png>)

- 機械翻訳や音声認識の機能がモデルのサイズ増加に対してスムーズに増加[40],とその一般化[67]
- 言語モデリングタスクのテスト損失パフォーマンスは、モデルのサイズ、データセットのサイズ、およびトレーニングの期間の関数としてスケーリング[44]
- その他のモダリティに対する生成モデル[24]
- text2code[39]
- few-shot の画像生成モデル[61]

影響は 3.1 で議論

推薦システムへの利用の可能性[付録 A.3]

2.2 特定の能力の急激な成長、

個別の能力は、全体平均と異なり急激な変化を示すことは十分に考えられる。
算術 [12]、言語理解 [35, 63]、プログラミング [5]で急激な能力の増加が見られた。

![Alt text](<第2問図表/Screenshot 2023-08-22 at 21.51.40.png>)

2.3 オープンエンドの入力の問題点

予測不能性は、有害な能力についても言える。潜在的に有害な能力が現れ、予測が困難な可能性があるかもしれない。
生成 AI は fine-tuning して使われることが多いが、振る舞いは完全に理解できない。

> AI Dungeon の事例：GPT-3 の fine-tuning を行ったが、特定の入力を使い任意のトピックについて話すように操作できた結果、GPT3 のバックドアアクセスを提供してしまった。

> 再犯予測の事例：再犯のデータについて人種を含むものと含まないものを用意して被告人を記述する簡単なプロンプトを生成し大規模生成モデルに判断させたところ、モデルサイズが大きくなると全体的な予測能力は向上したが、同時に黒人の偽陽性判定率が急激に大きくなった（下図）。

![Alt text](<第2問図表/Screenshot 2023-08-22 at 21.51.52.png>)

2.4 オープンエンドの出力の問題点

入力が固定されていても出力は多様（ただし、出力の多様性はすでに多くの研究がある）。

- distractive
- misleading
-

![Alt text](<第2問図表/Screenshot 2023-08-22 at 21.54.39.png>)
